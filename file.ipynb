{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file web scraps players data and teams data\n",
    "\n",
    "### First Installing the required modules\n",
    "* `BeautifulSoup` for web scraping\n",
    "* `pandas` for creating DataFrames to represent data in a structured format\n",
    "* `requests` for sending http requests to the web site\n",
    "* `json` to convert scraped data into json dictionary like format\n",
    "* `time` to prevent our code from sending multiple requests at once and reduce the load on the server\n",
    "* `functools` for `reduce()` function to allow for repeated list operations\n",
    "\n",
    "**You will also be required to install *`openpyxl`* for converting DataFrames to excel file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The url structure of [Pro Kabaddi Stats](https://www.prokabaddi.com/stats)\n",
    "\n",
    "The url structure the website very simple. It is as follows : https://www.prokabaddi.com/stats/{season_id}-{stats_id}-a-statistics  \n",
    "\n",
    "Every season has an **id** associated to it.  \n",
    "&emsp; > For Example **Season 9 has id as 25**  \n",
    "\n",
    "Every statistic type also has an **id** associated to it.  \n",
    "&emsp;> For Example **Total Points Scored by a Player has id as 102** and **Total Points Scored by a Team has id as 96**  \n",
    "\n",
    "So if we want to access the data of **Total Points Scored By a Team in Season 9**, then the url corresponding to that will be :  \n",
    "(https://www.prokabaddi.com/stats/25-96-a-statistics)  \n",
    "\n",
    "*```The url structure was understood by us manually after putting some hours into the website structure Pro Kabaddi```*  \n",
    "<br>\n",
    "The four dictionaries ```season_to_id, id_to_season, player_stats_to_id, teams_stats_to_id ``` represent just the information given above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "season_to_id={'Season 9': 25, 'Season 8': 20, 'Season 7': 11,\n",
    "              'Season 6': 10, 'Season 5': 8,  'Season 4': 4,  \n",
    "              'Season 3': 3,  'Season 2': 2,  'Season 1': 1,  \n",
    "              'All Seasons': 0}\n",
    "id_to_season={25: 'Season 9', 20: 'Season 8', 11: 'Season 7',\n",
    "              10: 'Season 6', 8: 'Season 5',  4: 'Season 4',\n",
    "              3: 'Season 3',  2: 'Season 2', 1: 'Season 1',\n",
    "              0: 'All Seasons'}\n",
    "player_stats_to_id={'total_points': 102, 'successful_raids': 21,\n",
    "                    'raid_points': 22, 'successful_tackles': 23,\n",
    "                    'tackle_points': 103, \n",
    "                    'do_or_die_raid_points': 132, 'super_raids': 104,\n",
    "                    'super_tackles': 28, 'super_10s': 100, 'high_5s': 101\n",
    "                    }\n",
    "teams_stats_to_id={'total_points': 96, 'successful_raids': 13,\n",
    "                   'raid_points': 97, 'successful_tackles': 15,\n",
    "                   'tackle_points': 95,\n",
    "                   'do_or_die_raid_points': 135, 'super_raids': 134,\n",
    "                   'super_tackles': 20, 'total_points_conceded': 133,\n",
    "                   'all_outs_inflicted': 136, 'all_out_conceded': 137\n",
    "                   }\n",
    "url='https://www.prokabaddi.com/stats/{0}-{1}-a-statistics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons_df=[]  #will contain dataframes for each season \n",
    "for season_name, season_id in season_to_id.items():\n",
    "    if season_name=='All Seasons':\n",
    "        continue\n",
    "    data_frames=[]     #will conatin dataframes for each stat_type for current season_name\n",
    "    for stat_type, stat_id in player_stats_to_id.items():\n",
    "        req=requests.get(url.format(season_id, stat_id))    #make request to the website\n",
    "        soup=BeautifulSoup(req.content,\"html.parser\")   # parse the html\n",
    "        new=soup.find_all('script')[4].string   #data is stored in the 5th script tag of the html page\n",
    "        new=new[new.find('{'):]  #so as to only fetch the json object and not the variable name\n",
    "        new2=json.loads(new)    # load the whole json object as python style dictionary\n",
    "        file=new2[\"stats\"][\"data\"]     #to only extract the relevant information\n",
    "        for record in file:  # this step is done to clean the data, add relevant columns, and remove redundant columns\n",
    "            record['season']=season_name\n",
    "            record[stat_type]=record['value'] \n",
    "            del record['value']\n",
    "            del record['team']\n",
    "            del record['rank']\n",
    "            del record['team_name']\n",
    "            del record['position_id']\n",
    "        data_frames.append(pd.DataFrame.from_dict(file))  # this give the dataframe for the current stat_type and season_name\n",
    "        time.sleep(3)   # 3 seconds are set as idle so that web server load is reduced\n",
    "    combined_data=reduce(lambda left, right: pd.merge(left, right, how='outer'), data_frames).fillna(0)     #combines all stat_types to give a single dataframe for the current season_name\n",
    "    all_seasons_df.append(combined_data)    # adds to the list of season_wise dataframes\n",
    "final_data_frame=pd.concat(all_seasons_df, ignore_index=True)   #combines all season dataframes to give a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons_df=[]\n",
    "for season_name, season_id in season_to_id.items():\n",
    "    if season_name=='All Seasons':\n",
    "        continue\n",
    "    data_frames=[]\n",
    "    for stat_type, stat_id in teams_stats_to_id.items():\n",
    "        req=requests.get(url.format(season_id, stat_id))\n",
    "        soup=BeautifulSoup(req.content, 'html.parser')\n",
    "        new=soup.find_all('script')[4].string \n",
    "        new=new[new.find('{'):] \n",
    "        new2=json.loads(new)    \n",
    "        file=new2[\"stats\"][\"data\"]\n",
    "        for record in file:\n",
    "            record['season']=season_name\n",
    "            record[stat_type]=record['value']\n",
    "            del record['value']\n",
    "            del record['rank']\n",
    "        data_frames.append(pd.DataFrame.from_dict(file))\n",
    "        time.sleep(1)\n",
    "    combined_data=reduce(lambda left, right: pd.merge(left, right, how='outer'), data_frames).fillna(0)\n",
    "    all_seasons_df.append(combined_data)\n",
    "teams_data=pd.concat(all_seasons_df, ignore_index=True)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing our data into excel\n",
    "```\n",
    "This cell will write the dataframe into an excel file.\n",
    "(openpyxl is used here)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame.to_excel('players_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_data.to_excel('teams_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2=\"https://feeds.prokabaddi.com/SI/{0}/Fixture.json\"\n",
    "url3=\"https://feeds.prokabaddi.com/SI/MatchCentre/{0}.json\"\n",
    "data_frames2=[]\n",
    "for season_name, season_id in season_to_id.items():\n",
    "    if season_name=='All Seasons':\n",
    "        continue\n",
    "    req=requests.get(url2.format(season_id))\n",
    "    new=json.loads(req.content)\n",
    "    file=new[\"matches\"]\n",
    "    for record in file:\n",
    "        req2=requests.get(url3.format(record['game_id']))\n",
    "        new_match=json.loads(req2.content)\n",
    "\n",
    "        record['toss_winner_id']=new_match[\"match_detail\"][\"toss\"][\"winner\"] \n",
    "        record['toss_choice']=new_match[\"match_detail\"][\"toss\"][\"selection\"]\n",
    "        if record['toss_choice']!='raid':\n",
    "            record['toss_choice']='court'\n",
    "            \n",
    "        record['venue_id']=new_match[\"match_detail\"][\"venue\"][\"id\"]\n",
    "        record['venue_name']=new_match[\"match_detail\"][\"venue\"][\"name\"]\n",
    "        if \"home_team_id\" in new_match[\"teams\"] and new_match['teams']['home_team_id']!=\"\" and new_match['teams']['home_team_id']!=\"0\" and new_match['teams']['home_team_id'] is not None:\n",
    "            record[\"home_team_id\"]=new_match[\"teams\"][\"home_team_id\"]\n",
    "            record['home_team_name']=new_match[\"teams\"][\"home_team_name\"]\n",
    "        else:\n",
    "            record[\"home_team_id\"]=0\n",
    "            record['home_team_name']=\"None\"\n",
    "\n",
    "\n",
    "\n",
    "        record['season']=season_name\n",
    "        \n",
    "        record[\"team1_name\"]=new_match['teams'][\"team\"][0][\"name\"]\n",
    "        record[\"team1_id\"]=new_match['teams'][\"team\"][0][\"id\"]\n",
    "        record[\"team1_score\"]=new_match['teams'][\"team\"][0][\"score\"]\n",
    "\n",
    "        record[\"team1_all_out_points\"]=new_match['teams'][\"team\"][0][\"stats\"][\"points\"][\"all_out\"]\n",
    "        record[\"team1_extra_points\"]=new_match['teams'][\"team\"][0][\"stats\"][\"points\"][\"extras\"]\n",
    "        record[\"team1_raid_points\"]=new_match['teams'][\"team\"][0][\"stats\"][\"points\"][\"raid_points\"][\"total\"]\n",
    "        record[\"team1_tackle_points\"]=new_match['teams'][\"team\"][0][\"stats\"][\"points\"][\"tackle_points\"][\"total\"]\n",
    "        \n",
    "        record[\"team1_raids_done\"]=new_match['teams'][\"team\"][0][\"stats\"][\"raids\"][\"total\"]\n",
    "        record[\"team1_successful_raids\"]=new_match['teams'][\"team\"][0][\"stats\"][\"raids\"][\"successful\"]\n",
    "        record[\"team1_unsuccessful_raids\"]=new_match['teams'][\"team\"][0][\"stats\"][\"raids\"][\"unsuccessful\"]\n",
    "        record[\"team1_empty_raids\"]=new_match['teams'][\"team\"][0][\"stats\"][\"raids\"][\"Empty\"]\n",
    "\n",
    "        record[\"team1_tackles_done\"]=new_match['teams'][\"team\"][0][\"stats\"][\"tackles\"][\"total\"]\n",
    "        record[\"team1_successful_tackles\"]=new_match['teams'][\"team\"][0][\"stats\"][\"tackles\"][\"successful\"]\n",
    "        record[\"team1_unsuccessful_tackles\"]=new_match['teams'][\"team\"][0][\"stats\"][\"tackles\"][\"unsuccessful\"]\n",
    "        \n",
    "        record[\"team1_all_outs\"]=new_match['teams'][\"team\"][0][\"stats\"][\"all_outs\"]\n",
    "        \n",
    "        \n",
    "\n",
    "        record[\"team2_name\"]=new_match['teams'][\"team\"][1][\"name\"]\n",
    "        record[\"team2_id\"]=new_match['teams'][\"team\"][1][\"id\"]\n",
    "        record[\"team2_score\"]=new_match['teams'][\"team\"][1][\"score\"]\n",
    "\n",
    "        record[\"team2_all_out_points\"]=new_match['teams'][\"team\"][1][\"stats\"][\"points\"][\"all_out\"]\n",
    "        record[\"team2_extra_points\"]=new_match['teams'][\"team\"][1][\"stats\"][\"points\"][\"extras\"]\n",
    "        record[\"team2_raid_points\"]=new_match['teams'][\"team\"][1][\"stats\"][\"points\"][\"raid_points\"][\"total\"]\n",
    "        record[\"team2_tackle_points\"]=new_match['teams'][\"team\"][1][\"stats\"][\"points\"][\"tackle_points\"][\"total\"]\n",
    "        \n",
    "        record[\"team2_raids_done\"]=new_match['teams'][\"team\"][1][\"stats\"][\"raids\"][\"total\"]\n",
    "        record[\"team2_successful_raids\"]=new_match['teams'][\"team\"][1][\"stats\"][\"raids\"][\"successful\"]\n",
    "        record[\"team2_unsuccessful_raids\"]=new_match['teams'][\"team\"][1][\"stats\"][\"raids\"][\"unsuccessful\"]\n",
    "        record[\"team2_empty_raids\"]=new_match['teams'][\"team\"][1][\"stats\"][\"raids\"][\"Empty\"]\n",
    "\n",
    "        record[\"team2_tackles_done\"]=new_match['teams'][\"team\"][1][\"stats\"][\"tackles\"][\"total\"]\n",
    "        record[\"team2_successful_tackles\"]=new_match['teams'][\"team\"][1][\"stats\"][\"tackles\"][\"successful\"]\n",
    "        record[\"team2_unsuccessful_tackles\"]=new_match['teams'][\"team\"][1][\"stats\"][\"tackles\"][\"unsuccessful\"]\n",
    "        \n",
    "        record[\"team2_all_outs\"]=new_match['teams'][\"team\"][1][\"stats\"][\"all_outs\"]\n",
    "        \n",
    "        \n",
    "        if('win_by_coin_toss' in record):\n",
    "            del record['win_by_coin_toss']\n",
    "\n",
    "        if (record[\"result_code\"] ==\"\"):\n",
    "            record[\"result_code\"]=\"W\"\n",
    "        elif record[\"result_code\"] in [\"Tied\",\"T\"]:\n",
    "            record[\"result_code\"]=\"T\"\n",
    "            record[\"event_sub_status\"]=\"Match Tied\"\n",
    "            record[\"winning_margin\"]=0\n",
    "        \n",
    "        delete_column=[\"venue_gmt_offset\", \"event_livecoverage\", \"event_duration_left\", \"result_sub_code\", \"event_is_daynight\",\n",
    "                       \"sport\", \"league_code\", \"event_state\", \"event_group\", \"event_islinkable\", \"tour_name\", \"event_status\",\n",
    "                       \"event_status_id\", \"event_stage\", \"series_name\", \"participants\", \"end_date\", \"tour_id\"]\n",
    "        for column in delete_column:\n",
    "            del record[column]\n",
    "        \n",
    "    data_frames2.append(pd.DataFrame.from_dict(file)) \n",
    "final_data_frame2=pd.concat(data_frames2, ignore_index=True)\n",
    "\n",
    "\n",
    "team1_wins=final_data_frame2['team1_score']>final_data_frame2['team2_score']\n",
    "team2_wins=final_data_frame2['team2_score']>final_data_frame2['team1_score']\n",
    "final_data_frame2[\"winning_team_name\"]=\"Match Tied\"\n",
    "final_data_frame2[\"winning_team_id\"]=0\n",
    "final_data_frame2.loc[team1_wins, 'winning_team_name']=final_data_frame2.loc[team1_wins, 'team1_name']\n",
    "final_data_frame2.loc[team2_wins, 'winning_team_name']=final_data_frame2.loc[team2_wins, 'team2_name']\n",
    "final_data_frame2.loc[team1_wins, 'winning_team_id']=final_data_frame2.loc[team1_wins, 'team1_id']\n",
    "final_data_frame2.loc[team2_wins, 'winning_team_id']=final_data_frame2.loc[team2_wins, 'team2_id']\n",
    "final_data_frame2.to_excel('match_data.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "venue name/home team name/team1 name/team 2 name/winning team name/ from hindi to english\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
