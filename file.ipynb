{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file web scraps players data and teams data\n",
    "\n",
    "### First Installing the required modules\n",
    "* `BeautifulSoup` for web scraping\n",
    "* `pandas` for creating DataFrames to represent data in a structured format\n",
    "* `requests` for sending http requests to the web site\n",
    "* `json` to convert scraped data into json dictionary like format\n",
    "* `time` to prevent our code from sending multiple requests at once and reduce the load on the server\n",
    "* `functools` for `reduce()` function to allow for repeated list operations\n",
    "\n",
    "**You will also be required to install *`openpyxl`* for converting DataFrames to excel file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The url structure of [Pro Kabaddi Stats](https://www.prokabaddi.com/stats)\n",
    "\n",
    "The url structure the website very simple. It is as follows : https://www.prokabaddi.com/stats/{season_id}-{stats_id}-a-statistics  \n",
    "\n",
    "Every season has an **id** associated to it.  \n",
    "&emsp; > For Example **Season 9 has id as 25**  \n",
    "\n",
    "Every statistic type also has an **id** associated to it.  \n",
    "&emsp;> For Example **Total Points Scored by a Player has id as 102** and **Total Points Scored by a Team has id as 96**  \n",
    "\n",
    "So if we want to access the data of **Total Points Scored By a Team in Season 9**, then the url corresponding to that will be :  \n",
    "(https://www.prokabaddi.com/stats/25-96-a-statistics)  \n",
    "\n",
    "*```The url structure was understood by us manually after putting some hours into the website structure Pro Kabaddi```*  \n",
    "<br>\n",
    "The four dictionaries ```season_to_id, id_to_season, player_stats_to_id, teams_stats_to_id ``` represent just the information given above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "season_to_id={'Season 9': 25, 'Season 8': 20, 'Season 7': 11,\n",
    "              'Season 6': 10, 'Season 5': 8,  'Season 4': 4,  \n",
    "              'Season 3': 3,  'Season 2': 2,  'Season 1': 1,  \n",
    "              'All Seasons': 0}\n",
    "id_to_season={25: 'Season 9', 20: 'Season 8', 11: 'Season 7',\n",
    "              10: 'Season 6', 8: 'Season 5',  4: 'Season 4',\n",
    "              3: 'Season 3',  2: 'Season 2', 1: 'Season 1',\n",
    "              0: 'All Seasons'}\n",
    "player_stats_to_id={'total_points': 102, 'successful_raids': 21,\n",
    "                    'raid_points': 22, 'successful_tackles': 23,\n",
    "                    'tackle_points': 103, \n",
    "                    'do_or_die_raid_points': 132, 'super_raids': 104,\n",
    "                    'super_tackles': 28, 'super_10s': 100, 'high_5s': 101\n",
    "                    }\n",
    "teams_stats_to_id={'total_points': 96, 'successful_raids': 13,\n",
    "                   'raid_points': 97, 'successful_tackles': 15,\n",
    "                   'tackle_points': 95,\n",
    "                   'do_or_die_raid_points': 135, 'super_raids': 134,\n",
    "                   'super_tackles': 20, 'total_points_conceded': 133,\n",
    "                   'all_outs_inflicted': 136, 'all_out_conceded': 137\n",
    "                   }\n",
    "url='https://www.prokabaddi.com/stats/{0}-{1}-a-statistics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons_df=[]  #will contain dataframes for each season \n",
    "for season_name, season_id in season_to_id.items():\n",
    "    if season_name=='All Seasons':\n",
    "        continue\n",
    "    data_frames=[]     #will conatin dataframes for each stat_type for current season_name\n",
    "    for stat_type, stat_id in player_stats_to_id.items():\n",
    "        req=requests.get(url.format(season_id, stat_id))    #make request to the website\n",
    "        soup=BeautifulSoup(req.content,\"html.parser\")   # parse the html\n",
    "        new=soup.find_all('script')[4].string   #data is stored in the 5th script tag of the html page\n",
    "        new=new[new.find('{'):]  #so as to only fetch the json object and not the variable name\n",
    "        new2=json.loads(new)    # load the whole json object as python style dictionary\n",
    "        file=new2[\"stats\"][\"data\"]     #to only extract the relevant information\n",
    "        for record in file:  # this step is done to clean the data, add relevant columns, and remove redundant columns\n",
    "            record[stat_type]=record['value'] \n",
    "            record['season']=season_name\n",
    "            del record['value']\n",
    "            del record['team']\n",
    "            del record['rank']\n",
    "            del record['team_name']\n",
    "            del record['position_id']\n",
    "        data_frames.append(pd.DataFrame.from_dict(file))  # this give the dataframe for the current stat_type and season_name\n",
    "        time.sleep(3)   # 3 seconds are set as idle so that web server load is reduced\n",
    "    combined_data=reduce(lambda left, right: pd.merge(left, right, how='outer'), data_frames).fillna(0)     #combines all stat_types to give a single dataframe for the current season_name\n",
    "    all_seasons_df.append(combined_data)    # adds to the list of season_wise dataframes\n",
    "final_data_frame=pd.concat(all_seasons_df, ignore_index=True)   #combines all season dataframes to give a single dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing our data into excel\n",
    "```\n",
    "This cell will write the dataframe into an excel file.\n",
    "(openpyxl is used here)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame.to_excel('players_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2=\"https://feeds.prokabaddi.com/SI/{0}/MastHead.json\"\n",
    "data_frames2=[]\n",
    "for season_name, season_id in season_to_id.items():\n",
    "    if season_name=='All Seasons':\n",
    "        continue\n",
    "    req=requests.get(url2.format(season_id))\n",
    "    new=json.loads(req.content)\n",
    "    file=new[\"matches\"]\n",
    "    for record in file:\n",
    "        if('win_by_coin_toss' in record):\n",
    "            del record['win_by_coin_toss']\n",
    "        del record[\"venue_gmt_offset\"]\n",
    "        del record[\"event_livecoverage\"]\n",
    "        del record[\"event_duration_left\"]\n",
    "        del record[\"result_sub_code\"]\n",
    "        del record[\"event_is_daynight\"]\n",
    "        del record[\"sport\"]\n",
    "        del record[\"league_code\"]\n",
    "        del record[\"event_state\"]\n",
    "        del record[\"event_group\"]\n",
    "        del record[\"event_islinkable\"]\n",
    "\n",
    "        #write code to delete all the records with duplicate game-id\n",
    "\n",
    "        del record[\"event_status\"]\n",
    "        del record[\"event_status_id\"]\n",
    "        del record[\"event_stage\"]\n",
    "        del record[\"series_name\"]\n",
    "        \n",
    "\n",
    "        if (record[\"result_code\"] ==\"\"):\n",
    "            record[\"result_code\"]=\"W\"\n",
    "        elif record[\"result_code\"]==\"Tied\":\n",
    "            record[\"result_code\"]=\"T\"\n",
    "    \n",
    "        record[\"team1_name\"]=record['participants'][0][\"name\"]\n",
    "        record[\"team1_id\"]=record['participants'][0][\"id\"]\n",
    "        record[\"team1_score\"]=record['participants'][0][\"value\"]\n",
    "        record[\"team2_name\"]=record['participants'][1][\"name\"]\n",
    "        record[\"team2_id\"]=record['participants'][1][\"id\"]\n",
    "        record[\"team2_score\"]=record['participants'][1][\"value\"]\n",
    "        del record[\"participants\"]\n",
    "           \n",
    "    data_frames2.append(pd.DataFrame.from_dict(file)) \n",
    "    time.sleep(1)\n",
    "final_data_frame2=pd.concat(data_frames2, ignore_index=True) \n",
    "final_data_frame2.to_excel('match_data.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
